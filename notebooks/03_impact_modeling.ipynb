{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffe53815",
   "metadata": {},
   "source": [
    "# ðŸ“Š Notebook: Event Impact Modeling\n",
    "**Task:** 3 â€“ Build the Event-Indicator Association Matrix  \n",
    "**Objective:** To quantify how specific events (Policies, Product Launches, Infrastructure) shift the trajectory of financial inclusion indicators.\n",
    "\n",
    "### ðŸ§  The Logic: The \"Event-Augmented\" Forecast\n",
    "Standard time-series models (ARIMA/Prophet) rely on long history. We don't have that (only 5 data points).\n",
    "Instead, we will use a **Structural Scenario Model**:\n",
    "\n",
    "$$ Y_{t} = Y_{trend} + \\sum (Event_{impact} \\times Decay_{factor}) $$\n",
    "\n",
    "Where:\n",
    "*   **$Y_{trend}$**: The natural organic growth (e.g., population growth, gradual adoption).\n",
    "*   **$Event_{impact}$**: A one-time or permanent shift caused by a shock (e.g., M-Pesa Launch).\n",
    "*   **$Decay_{factor}$**: How long it takes for the event to reach full potential (Lag).\n",
    "\n",
    "In this notebook, we calculate the values for **$Event_{impact}$**.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a272184e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 12 Events and 14 Impact Links.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Visual Config\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# 1. Load Processed Data (Observations + Events)\n",
    "df = pd.read_csv('../data/processed/ethiopia_fi_enriched.csv', parse_dates=['observation_date'])\n",
    "\n",
    "# 2. Load Impact Links (The \"Logic\" Sheet)\n",
    "# We need to reload the raw Excel to get the Impact_sheet, or load a CSV if you saved it separately.\n",
    "# Assuming we load from raw for this specific sheet as it wasn't modified in Task 1, \n",
    "# OR if you saved it in Task 1, load from processed. \n",
    "# Here we stick to the raw loader for the specific sheet to be safe.\n",
    "try:\n",
    "    from src.loader import load_data\n",
    "    impact_df = load_data('../data/raw/ethiopia_fi_unified_data.xlsx', sheet_name='Impact_sheet')\n",
    "except Exception as e:\n",
    "    # Fallback if src not found (running directly)\n",
    "    print(\"âš ï¸ Loader not found, using direct pandas read\")\n",
    "    impact_df = pd.read_excel('../data/raw/ethiopia_fi_unified_data.xlsx', sheet_name='Impact_sheet')\n",
    "\n",
    "# Filter main DF into Events and Observations\n",
    "events_df = df[df['record_type'] == 'event'].copy()\n",
    "observations_df = df[df['record_type'] == 'observation'].copy()\n",
    "\n",
    "print(f\"âœ… Loaded {len(events_df)} Events and {len(impact_df)} Impact Links.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b88b6b",
   "metadata": {},
   "source": [
    "## 2. Build the Event-Indicator Matrix\n",
    "We need to join the `Events` (Which *Date*?) with the `Impact Links` (Which *Effect*?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06a383c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['event_name'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 1. Merge Impact Links with Event Details\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# We join on 'parent_id' (Impact Sheet) == 'record_id' (Data Sheet)\u001b[39;00m\n\u001b[32m      3\u001b[39m full_impact_df = pd.merge(\n\u001b[32m      4\u001b[39m     impact_df,\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mevents_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrecord_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mevent_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mobservation_date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcategory\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[32m      6\u001b[39m     left_on=\u001b[33m'\u001b[39m\u001b[33mparent_id\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      7\u001b[39m     right_on=\u001b[33m'\u001b[39m\u001b[33mrecord_id\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      8\u001b[39m     how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 2. Clean up columns for the Matrix View\u001b[39;00m\n\u001b[32m     12\u001b[39m matrix_cols = [\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mevent_name\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mobservation_date\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mindicator_code\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mimpact_direction\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     15\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mimpact_magnitude\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mimpact_estimate\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlag_months\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnotes\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     16\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\natty\\Downloads\\KAIM\\ethiopia-fi-forecast\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\natty\\Downloads\\KAIM\\ethiopia-fi-forecast\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\natty\\Downloads\\KAIM\\ethiopia-fi-forecast\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['event_name'] not in index\""
     ]
    }
   ],
   "source": [
    "# 1. Merge Impact Links with Event Details\n",
    "# We join on 'parent_id' (Impact Sheet) == 'record_id' (Data Sheet)\n",
    "full_impact_df = pd.merge(\n",
    "    impact_df,\n",
    "    events_df[['record_id', 'event_name', 'observation_date', 'category']],\n",
    "    left_on='parent_id',\n",
    "    right_on='record_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 2. Clean up columns for the Matrix View\n",
    "matrix_cols = [\n",
    "    'event_name', 'category', 'observation_date', \n",
    "    'indicator_code', 'impact_direction', \n",
    "    'impact_magnitude', 'impact_estimate', 'lag_months', 'notes'\n",
    "]\n",
    "\n",
    "# Filter for rows where we actually have a match\n",
    "impact_matrix = full_impact_df[matrix_cols].dropna(subset=['event_name'])\n",
    "\n",
    "print(\"Sample Impact Matrix:\")\n",
    "display(impact_matrix.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3cb520",
   "metadata": {},
   "source": [
    "### 3.1 Analyzing the Conversion Rate\n",
    "Telebirr reports ~47 Million users. Findex reports 49% of adults.\n",
    "If the population of adults (15+) is ~60 Million:\n",
    "*   49% = ~29.4 Million people.\n",
    "*   Telebirr claims 47 Million users.\n",
    "\n",
    "**Insight:** There are more Telebirr accounts than total unique financial accounts. This proves that **1 Telebirr User $\\neq$ 1 New Included Person**. Most Telebirr users likely already had bank accounts, or have the app but don't use it enough to count for Findex.\n",
    "\n",
    "We will calculate a **Conservative Impact Coefficient**.\n",
    "Hypothesis: Telebirr contributed to the 3pp growth between 2021 (46%) and 2024 (49%).\n",
    "*   Growth: +3% of 60M adults = 1.8M new unique users.\n",
    "*   Telebirr Users added: ~40M.\n",
    "*   **Conversion Ratio**: 1.8M / 40M $\\approx$ **4.5%**.\n",
    "\n",
    "**Model Assumption**: For every 100 new Mobile Money registrations, Account Ownership (Access) increases by roughly **4.5 people**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee75a029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Mobile-to-Findex Conversion Rate: 0.0450 (4.5%)\n"
     ]
    }
   ],
   "source": [
    "# Define our Derived Parameters\n",
    "ADULT_POPULATION = 60_000_000 # Estimate\n",
    "TELEBIRR_USERS_ADDED = 40_000_000 # Approx 2021-2024\n",
    "FINDEX_USERS_ADDED = ADULT_POPULATION * 0.03 # 3% growth\n",
    "\n",
    "CONVERSION_RATE = FINDEX_USERS_ADDED / TELEBIRR_USERS_ADDED\n",
    "print(f\"Calculated Mobile-to-Findex Conversion Rate: {CONVERSION_RATE:.4f} ({CONVERSION_RATE*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502bb334",
   "metadata": {},
   "source": [
    "## 4. Building the Association Matrix\n",
    "\n",
    "We now map this logic to other events.\n",
    "*   **Telebirr**: Validated (Low conversion impact on Access, High impact on Usage).\n",
    "*   **M-Pesa**: Market entrant Aug 2023. We assume similar physics to Telebirr.\n",
    "*   **NBE Liberalization**: Policy change. Enabler for M-Pesa.\n",
    "\n",
    "We will create a matrix merging the raw `events` with `Impact_sheet` and filling in the estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9d90a2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['event_id', 'event_name', 'event_date'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 1. Merge Events and Impacts\u001b[39;00m\n\u001b[32m      2\u001b[39m event_impact_df = pd.merge(\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mevents\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mevent_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mevent_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mevent_date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcategory\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[32m      4\u001b[39m     impacts_raw,\n\u001b[32m      5\u001b[39m     left_on=\u001b[33m'\u001b[39m\u001b[33mevent_id\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      6\u001b[39m     right_on=\u001b[33m'\u001b[39m\u001b[33mparent_id\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      7\u001b[39m     how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 2. Refine Estimates based on our Calculation\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# We update the 'impact_magnitude' for Mobile Money launches based on the conversion rate\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# If Magnitude is missing (NaN), we impute it.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mestimate_magnitude\u001b[39m(row):\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# If we already have a manual estimate in the excel, keep it\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\natty\\Downloads\\KAIM\\ethiopia-fi-forecast\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\natty\\Downloads\\KAIM\\ethiopia-fi-forecast\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\natty\\Downloads\\KAIM\\ethiopia-fi-forecast\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['event_id', 'event_name', 'event_date'] not in index\""
     ]
    }
   ],
   "source": [
    "# 1. Merge Events and Impacts\n",
    "event_impact_df = pd.merge(\n",
    "    events[['event_id', 'event_name', 'event_date', 'category']],\n",
    "    impacts_raw,\n",
    "    left_on='event_id',\n",
    "    right_on='parent_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 2. Refine Estimates based on our Calculation\n",
    "# We update the 'impact_magnitude' for Mobile Money launches based on the conversion rate\n",
    "# If Magnitude is missing (NaN), we impute it.\n",
    "\n",
    "def estimate_magnitude(row):\n",
    "    # If we already have a manual estimate in the excel, keep it\n",
    "    if pd.notnull(row['impact_magnitude']):\n",
    "        return row['impact_magnitude']\n",
    "    \n",
    "    # Logic for M-Pesa (Product Launch)\n",
    "    if 'M-Pesa' in row['event_name'] and row['related_indicator'] == 'ACC_OWNERSHIP':\n",
    "        # Assumption: Safaricom targets 10M users.\n",
    "        # Impact = 10M * Conversion_Rate / Adult_Pop\n",
    "        target_users = 10_000_000\n",
    "        impact_pp = (target_users * CONVERSION_RATE) / ADULT_POPULATION * 100\n",
    "        return impact_pp # Returns percentage points (e.g., 0.75)\n",
    "\n",
    "    return 0.0\n",
    "\n",
    "event_impact_df['calculated_impact'] = event_impact_df.apply(estimate_magnitude, axis=1)\n",
    "\n",
    "# 3. Create the Matrix View\n",
    "association_matrix = event_impact_df.pivot_table(\n",
    "    index=['event_date','event_name'],\n",
    "    columns='related_indicator',\n",
    "    values='calculated_impact'\n",
    ").fillna(0)\n",
    "\n",
    "print(\"Association Matrix (Estimated Impact in Percentage Points):\")\n",
    "display(association_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5109a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
